{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7caa50ba",
   "metadata": {},
   "source": [
    "# U.S. Geological Survey Class GW3099\n",
    "Advanced Modeling of Groundwater Flow (GW3099)\\\n",
    "Boise, Idaho\\\n",
    "September 16 - 20, 2024\n",
    "\n",
    "![title](../../../images/ClassLocation.jpg)\n",
    "\n",
    "## Setting up and Running Prior Monte Carlo and PEST++"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06518042",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "import flopy as fp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyemu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b710c3",
   "metadata": {},
   "source": [
    "### *quick note* - if you want to fiddle with options, you can change where you will write the results by setting the following variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678fe68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rundir = Path(\"../tmprun\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7523cc86",
   "metadata": {},
   "source": [
    "### We are going to make heavy use of python and `pyemu` (basically the `flopy` of the PEST world). There are a couple more high-level (but more abstract) ways to do this that are powerful and performant. In particular, one is `PstFrom` which is discussed in this [GMDSI Tutorial](https://github.com/gmdsi/GMDSI_notebooks/tree/main/tutorials/part2_01_pstfrom_pest_setup). Also, a new advance in parameterization is in the [`pypestutils`](https://github.com/pypest/pypestutils) package we we will touch on a bit later.\n",
    "\n",
    "### For now, though, we will work through \"the hard way\" to better see what we are actually doing. #showyerwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a064e278-36c8-429a-aed2-543647eaa41e",
   "metadata": {},
   "source": [
    "## So, first up we need to define a location for the background files to start with, and a setup directory to copy to and work in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e40df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_d = Path(\"../pest_background_files/\")\n",
    "t_d = Path(\"../pest_ies_setup\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if t_d.exists():\n",
    "    shutil.rmtree(t_d)\n",
    "shutil.copytree(org_d, t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923f7dfd",
   "metadata": {},
   "source": [
    "### Let's start out with pilot points for HK in the aquifer and the clay layer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b585e264",
   "metadata": {},
   "source": [
    "### get spatial reference for the model - pilot points are based on geographic coordinates (not on layer/row/column)\n",
    "\n",
    "More information on pilot point parameterization at this [GMDSI Tutorial](https://github.com/gmdsi/GMDSI_notebooks/tree/main/tutorials/part1_07_pilotpoints_setup) or in this [USGS Scientific Investigations Report](https://pubs.usgs.gov/sir/2010/5168/pdf/sir20105168.pdf)\n",
    "![image.png](./pp.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f82424d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = fp.mf6.MFSimulation.load(sim_ws=str(t_d))\n",
    "gwf = sim.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b4508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = pyemu.helpers.SpatialReference.from_namfile(\n",
    "    str(t_d / \"at.nam\"), delr=gwf.dis.delr.array, delc=gwf.dis.delc.array\n",
    ")\n",
    "sr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341adf62",
   "metadata": {},
   "source": [
    "### set up variograms for K pilot points\n",
    "\n",
    "For more background on variograms and geostatistics, check out this [GMDSI tutorial](https://github.com/gmdsi/GMDSI_notebooks/tree/main/tutorials/part0_intro_to_geostatistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8e4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_aq = 3\n",
    "# exponential variogram for spatially varying parameters\n",
    "v_aq = pyemu.geostats.ExpVario(\n",
    "    contribution=1.0,  # sill\n",
    "    a=pp_aq\n",
    "    * 3\n",
    "    * sr.delc[\n",
    "        0\n",
    "    ],  # range of correlation; length units of the model. In our case 'meters'\n",
    "    anisotropy=1.0,  # name says it all\n",
    "    bearing=0.0,  # angle in degrees East of North corresponding to anisotropy ellipse\n",
    ")\n",
    "\n",
    "# geostatistical structure for spatially varying parameters\n",
    "aq_gs = pyemu.geostats.GeoStruct(variograms=v_aq, transform=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd7e6c3-c122-4a58-98dd-a48acee0cfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_aq.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20d1937",
   "metadata": {},
   "outputs": [],
   "source": [
    "pp_clay = 6\n",
    "# exponential variogram for spatially varying parameters\n",
    "v_clay = pyemu.geostats.ExpVario(\n",
    "    contribution=1.0,  # sill\n",
    "    a=pp_clay\n",
    "    * 5\n",
    "    * sr.delc[\n",
    "        0\n",
    "    ],  # range of correlation; length units of the model. In our case 'meters'\n",
    "    anisotropy=1.0,  # name says it all\n",
    "    bearing=0.0,  # angle in degrees East of North corresponding to anisotropy ellipse\n",
    ")\n",
    "\n",
    "# geostatistical structure for spatially varying parameters\n",
    "clay_gs = pyemu.geostats.GeoStruct(variograms=v_clay, transform=\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dde88c4-a101-4d25-94f4-cdbd10902839",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_clay.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afe4c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ib = gwf.dis.idomain.array[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4222c3ea",
   "metadata": {},
   "source": [
    "### we only need pilot points for two unique K files - k_aq and k_clay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1678f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_aq = np.loadtxt(t_d / \"k_aq.ref\")\n",
    "k_clay = np.loadtxt(t_d / \"k_clay.ref\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d0e49c-6a65-4fa8-af24-af4be45799e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(8, 4))\n",
    "c = ax[0].imshow(k_aq)\n",
    "plt.colorbar(c, ax=ax[0])\n",
    "ax[0].set_title(\"aquifer\")\n",
    "c1 = ax[1].imshow(k_clay)\n",
    "plt.colorbar(c1, ax=ax[1])\n",
    "ax[1].set_title(\"clay\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b57295-c924-4533-8af5-ed0fee4fcc3c",
   "metadata": {},
   "source": [
    "### we can define spatial zones based on the initial K values, assuming they are grouped as homogeneous and unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66afa108",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_aq = np.unique(k_aq)\n",
    "aq_zones_dict = dict(zip(np.arange(1, len(uniq_aq) + 1), uniq_aq))\n",
    "aq_zones_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57b85bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "uniq_clay = np.unique(k_clay)\n",
    "clay_zones_dict = dict(zip(np.arange(1, len(uniq_clay) + 1), uniq_clay))\n",
    "clay_zones_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4f1fd4-63bc-43b9-8951-f4d8ceb45eaa",
   "metadata": {},
   "source": [
    "### make integer arrays of zones for the unique values of the aquifer ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06adf3d2-4de7-4289-b02f-63b478a09f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_zones = np.zeros_like(k_aq)\n",
    "for ck, cv in aq_zones_dict.items():\n",
    "    aq_zones[k_aq == cv] = ck"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d947275d-9113-4830-b515-6281657249f6",
   "metadata": {},
   "source": [
    "### ... and the clay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95494bf4-e7f4-4877-b2c0-e8d898136da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# only put pilot points in the clay where the clay is actually present\n",
    "clay_zones = np.zeros_like(k_aq)\n",
    "clay_zones[k_clay == clay_zones_dict[1]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad060d4-1dd8-4ec0-a177-96f523de7c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 2, figsize=(8, 6))\n",
    "ax = ax.ravel()\n",
    "c = ax[0].imshow(k_aq)\n",
    "plt.colorbar(c, ax=ax[0])\n",
    "ax[0].set_title(\"K aquifer\")\n",
    "c1 = ax[1].imshow(k_clay)\n",
    "plt.colorbar(c1, ax=ax[1])\n",
    "ax[1].set_title(\"K clay\")\n",
    "\n",
    "c2 = ax[2].imshow(aq_zones)\n",
    "plt.colorbar(c2, ax=ax[2])\n",
    "ax[2].set_title(\"Zones aquifer\")\n",
    "\n",
    "c3 = ax[3].imshow(clay_zones)\n",
    "plt.colorbar(c3, ax=ax[3])\n",
    "ax[3].set_title(\"Zones clay\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0584f0",
   "metadata": {},
   "source": [
    "## let's set up pilot points for the k files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a786de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_pp_df = pyemu.pp_utils.setup_pilotpoints_grid(\n",
    "    sr=sr,  # model spatial reference\n",
    "    ibound=aq_zones,  # to which cells to setup ppoints\n",
    "    # ibound=np.ones_like(aq_zones),\n",
    "    prefix_dict={0: [\"hk_aq\"]},  # prefix to add to parameter names\n",
    "    pp_dir=t_d,\n",
    "    tpl_dir=t_d,\n",
    "    shapename=str(t_d / \"pp_aq.shp\"),\n",
    "    use_ibound_zones=True,\n",
    "    every_n_cell=pp_aq,\n",
    ")  # pilot point spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b77f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=aq_pp_df.x, y=aq_pp_df.y, c=aq_pp_df.zone)\n",
    "plt.axis(\"square\")\n",
    "plt.xlim([0, 12500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21a604b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clay_pp_df = pyemu.pp_utils.setup_pilotpoints_grid(\n",
    "    sr=sr,  # model spatial reference\n",
    "    ibound=clay_zones,  # to which cells to setup ppoints\n",
    "    prefix_dict={0: [\"hk_clay\"]},  # prefix to add to parameter names\n",
    "    pp_dir=t_d,\n",
    "    tpl_dir=t_d,\n",
    "    shapename=str(t_d / \"pp_clay.shp\"),\n",
    "    use_ibound_zones=True,\n",
    "    every_n_cell=pp_clay,\n",
    ")  # pilot point spacing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa719032",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x=clay_pp_df.x, y=clay_pp_df.y, c=clay_pp_df.zone)\n",
    "plt.axis(\"square\")\n",
    "plt.ylim([0, 20000])\n",
    "plt.xlim([0, 12500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e38c763",
   "metadata": {},
   "source": [
    "### Now we make an `OrdinaryKrige` object for each pilot point network. This holds the information needed for setting up interpolation, and also has methods to perform the interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3d8e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_aq = pyemu.geostats.OrdinaryKrige(\n",
    "    aq_gs, aq_pp_df.loc[aq_pp_df.pargp == \"hk_aq\"]\n",
    ")\n",
    "ok_clay = pyemu.geostats.OrdinaryKrige(\n",
    "    clay_gs, clay_pp_df.loc[clay_pp_df.pargp == \"hk_clay\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca010d56",
   "metadata": {},
   "source": [
    "### We need factors for the interpolation here. Basically a set of weights for each grid cell, based on distance from the nearest pilot points, from which a weighted average of pilot point values is used to calculate the value in each cell. The function of weight by distance is informed by the variogram above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82425ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "aq_fac_df = ok_aq.calc_factors_grid(\n",
    "    sr,\n",
    "    minpts_interp=1,\n",
    "    maxpts_interp=10,\n",
    ")\n",
    "clay_fac_df = ok_clay.calc_factors_grid(\n",
    "    sr,\n",
    "    minpts_interp=1,\n",
    "    maxpts_interp=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa37160f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just gotta save these factors out to a file\n",
    "ok_aq.to_grid_factors_file(str(t_d / \"pp_aq.fac\"))\n",
    "ok_clay.to_grid_factors_file(str(t_d / \"pp_clay.fac\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e14807",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t_d.glob(\"*.fac\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93593257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's check out all the useful information we have in factors dataframe\n",
    "aq_fac_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4febd8",
   "metadata": {},
   "source": [
    "# now make a PST file to pull this all together\n",
    "### recall the general structure of the PST interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e1201fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "display(Image(url=\"../background/pest_flow1.gif\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8ad54d",
   "metadata": {},
   "source": [
    "### so, let's have a look at the interface files (`tpl` and `ins`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec59d02b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t_d.glob(\"*.tpl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303d35b5",
   "metadata": {},
   "source": [
    "### So we have two `pp` related `tpl` files, and some homebrewed other ones made ahead of time. Let's check those out as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dabfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here's the river file - looks like we gonna\n",
    "# parameterize conductance as homog (is that cool???)\n",
    "[print(i.strip()) for i in open(t_d / \"riv.ref.tpl\", \"r\").readlines()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c95d68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rch is easy - just a constant value\n",
    "[print(i.strip()) for i in open(t_d / \"at.rch.tpl\", \"r\").readlines()];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe293d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# npf has some shenanigans going on\n",
    "[print(i.strip()) for i in open(t_d / \"at.npf.tpl\", \"r\").readlines()];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ea0bf7",
   "metadata": {},
   "source": [
    "#### for `npf`, we have just the two files we assume are being made my the pilot point interpolation - `k_aq.ref` for the aquifer and `k_clay.ref` for the clay. These two files get assigned across the 5 layers based on lithology. Not a bad idea! Then the `FACTOR` capability is used to assign a fraction to anisotropy for `k33` (queue Alden's dance). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6375a",
   "metadata": {},
   "source": [
    "#### how about `ins` files?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbff941",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(t_d.glob(\"*.ins\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa607fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# just the one we made in the previous notebook\n",
    "[print(i.strip()) for i in open(t_d / \"allobs.dat.ins\", \"r\").readlines()];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1e714c",
   "metadata": {},
   "source": [
    "#### OK! Given all this info, the method below (`Pst.from_io_files`) reads all the `tpl` and `ins` files in a directory, scrapes the parameter and observation information from them, and populated a `Pst` object in memory that contains defaults and specifics covering basically everything the PEST interface will, ultimately, need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f435b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = Path(os.getcwd())\n",
    "os.chdir(t_d)\n",
    "pst = pyemu.Pst.from_io_files(*pyemu.helpers.parse_dir_for_io_files(\".\"))\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1337c24",
   "metadata": {},
   "source": [
    "### Both the `parameter_data` and `observation_data` are populated as `pandas DataFrames` (i know, easier if `recarrays` but....) so you can view and change values easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c341b7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars = pst.parameter_data\n",
    "pars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b2b299",
   "metadata": {},
   "source": [
    "### We need to set meaningful starting values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48aaa9d1",
   "metadata": {},
   "source": [
    "### first set constant parameter values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf86a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.parnme.str.contains(\"aniso\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc5fb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[\"rv1\", \"parval1\"] = 1e05  # starting value\n",
    "pars.loc[\"rv1\", \"parlbnd\"] = 1e03  # lower bound\n",
    "pars.loc[\"rv1\", \"parubnd\"] = 1e06  # upper bound\n",
    "pars.loc[\"rv1\", \"pargp\"] = \"riv_cond\"  # group (same for those below)\n",
    "\n",
    "pars.loc[\"rch\", \"parval1\"] = 0.003641\n",
    "pars.loc[\"rch\", \"parlbnd\"] = 0.003641 * 0.9\n",
    "pars.loc[\"rch\", \"parubnd\"] = 0.003641 * 1.1\n",
    "pars.loc[\"rch\", \"pargp\"] = \"rch\"\n",
    "\n",
    "pars.loc[\"kaniso\", \"parval1\"] = 0.2\n",
    "pars.loc[\"kaniso\", \"parlbnd\"] = 0.001\n",
    "pars.loc[\"kaniso\", \"parubnd\"] = 0.85\n",
    "pars.loc[\"kaniso\", \"pargp\"] = \"anisotropy\"\n",
    "\n",
    "pars.loc[\"kaniso_clay\", \"parval1\"] = 0.5\n",
    "pars.loc[\"kaniso_clay\", \"parlbnd\"] = 0.001\n",
    "pars.loc[\"kaniso_clay\", \"parubnd\"] = 0.85\n",
    "pars.loc[\"kaniso_clay\", \"pargp\"] = \"anisotropy_clay\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc682e9",
   "metadata": {},
   "source": [
    "### next let's use the \"zone\" information from the pilot points to assign groups by array _and_ zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f44c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[~pars.zone.isnull(), \"pargp\"] = [\n",
    "    f\"{i.split('_i:')[0]}_{int(float(z))}\"\n",
    "    for i, z in zip(\n",
    "        pars.loc[~pars.zone.isnull()].parnme,\n",
    "        pars.loc[~pars.zone.isnull()].zone,\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "979eb3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.zone = [float(i) for i in pars.zone]\n",
    "pars.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7ec8608",
   "metadata": {},
   "source": [
    "### Without enforcing too much structure, we can adjust a few starting values and bounds to inform ies of at least some of the general patterns of K values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8766150",
   "metadata": {},
   "outputs": [],
   "source": [
    "pars.loc[pars.pargp.str.contains(\"hk_aq\"), \"parval1\"] = 200\n",
    "pars.loc[pars.pargp.str.contains(\"hk_aq\"), \"parlbnd\"] = 0.01\n",
    "pars.loc[pars.pargp.str.contains(\"hk_aq\"), \"parubnd\"] = 1e3\n",
    "pars.loc[pars.pargp.str.contains(\"hk_clay\"), \"parval1\"] = 1\n",
    "pars.loc[pars.pargp.str.contains(\"hk_clay\"), \"parlbnd\"] = 0.0001\n",
    "pars.loc[pars.pargp.str.contains(\"hk_clay\"), \"parubnd\"] = 1e2\n",
    "pars.loc[pars.pargp == \"hk_aq_5\", \"parval1\"] = 200\n",
    "pars.loc[pars.pargp == \"hk_aq_4\", \"parval1\"] = 200\n",
    "pars.loc[pars.pargp == \"hk_aq_3\", \"parval1\"] = 200\n",
    "pars.loc[pars.pargp == \"hk_aq_4\", \"parubnd\"] = 750\n",
    "pars.loc[pars.pargp == \"hk_aq_3\", \"parubnd\"] = 500\n",
    "pars.loc[pars.pargp == \"hk_clay_1\", \"parval1\"] = 1\n",
    "pars.loc[pars.pargp == \"hk_clay_2\", \"parval1\"] = 150\n",
    "pars.loc[pars.pargp == \"hk_clay_2\", \"parlbnd\"] = 1\n",
    "pars.loc[pars.pargp == \"hk_clay_2\", \"parubnd\"] = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f05700d",
   "metadata": {},
   "source": [
    "## next we need to read in the observation values (the known values that is) and set them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b7ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "obsvals = pd.read_csv(t_d / \"obsvalues.dat\", sep=r\"\\s+\", index_col=0)\n",
    "obsvals.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62106c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c96dd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data[\"standard_deviation\"] = -99999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3182a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data.loc[obsvals.index, \"obgnme\"] = obsvals.obgnme\n",
    "pst.observation_data.loc[obsvals.index, \"obsval\"] = obsvals.obsval\n",
    "pst.observation_data.loc[obsvals.index, \"weight\"] = obsvals.weight\n",
    "\n",
    "pst.observation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fbe507",
   "metadata": {},
   "source": [
    "### we need to set standard deviation values for the observations to account for their uncertainty. This uncertainty stems from multiple sources including measurement error, the process of assigning a single value to represent more than an infinitesimal snapshot in space and time, model imperfections, etc. etc. It may seem like we don't know anything!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40df747d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for heads, let's go with 0.25 m\n",
    "pst.observation_data.loc[\n",
    "    obsvals.obgnme == \"headgroup\", \"standard_deviation\"\n",
    "] = 0.25\n",
    "# for head differences, this can be lower as the values are quite a bit lower as well\n",
    "pst.observation_data.loc[\n",
    "    obsvals.obgnme == \"headdiffgroup\", \"standard_deviation\"\n",
    "] = 0.025\n",
    "# for the river flux and lake flux observations, we can assume 10% error around the observed values\n",
    "pst.observation_data.loc[\n",
    "    ~obsvals.obgnme.str.contains(\"head\"), \"standard_deviation\"\n",
    "] = 0.1 * np.abs(\n",
    "    pst.observation_data.loc[~obsvals.obgnme.str.contains(\"head\"), \"obsval\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbe9f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.observation_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27cb2cb",
   "metadata": {},
   "source": [
    "### now we need to write out the `forward_run` script that includes pilot point interpolation, running MF6, and postprocesses the observations to prepare them for reading\n",
    "\n",
    "#### this is hella meta - writing python using python. careful with quote marks!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d8a44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(t_d / \"forward_run.py\", \"w\") as f:\n",
    "    # add imports\n",
    "    f.write(\n",
    "        \"import os\\nimport shutil\\nimport numpy as np\\nimport pyemu\\nimport flopy\\n\"\n",
    "    )\n",
    "    f.write(\"import pandas as pd\\n\")\n",
    "    # preprocess pilot points to grid\n",
    "    f.write(\n",
    "        \"_ = pyemu.geostats.fac2real('hk_aqpp.dat', factors_file='pp_aq.fac',out_file='k_aq.ref')\\n\"\n",
    "    )\n",
    "    f.write(\n",
    "        \"_ = pyemu.geostats.fac2real('hk_claypp.dat', factors_file='pp_clay.fac',out_file='k_clay.ref')\\n\"\n",
    "    )\n",
    "    # run MF6\n",
    "    f.write(\"pyemu.os_utils.run('mf6')\\n\")\n",
    "    # process the observations\n",
    "    # remember to sort the glob results!\n",
    "    outfiles = [\n",
    "        f\"./{i.name}\"\n",
    "        for i in sorted(list(Path(\"../pest_obs_prototype\").glob(\"*.csv\")))\n",
    "    ]\n",
    "    f.write(f\"outfiles = {outfiles}\\n\")\n",
    "    f.write(\"obs = pd.concat([pd.read_csv(i).T.iloc[1:] for i in outfiles])\\n\")\n",
    "    f.write(\n",
    "        \"obs.loc['DS'] = obs.loc['DS'] + obs.loc['PF']\\n\"\n",
    "    )  # note that we have to add the two river obs\n",
    "    f.write(\n",
    "        \"obs.loc['UW02'] = obs.loc['U02']-obs.loc['W02']\\n\"\n",
    "    )  # head difference targets\n",
    "    f.write(\n",
    "        \"obs.loc['UW08'] = obs.loc['U08']-obs.loc['W08']\\n\"\n",
    "    )  # head difference targets\n",
    "    f.write(\n",
    "        \"obs.loc['UW15'] = obs.loc['U15']-obs.loc['W15']\\n\"\n",
    "    )  # head difference targets\n",
    "    f.write(\"obs.columns=['obsname']\\n\")\n",
    "    f.write('obs.to_csv(\"allobs.dat\", sep = \" \")')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40239e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# so how does it look?\n",
    "[print(i.strip()) for i in open(t_d / \"forward_run.py\", \"r\").readlines()];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff79fa3",
   "metadata": {},
   "source": [
    "### now set a few ies-specific values and write out the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015fac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.model_command = [\"python forward_run.py\"]\n",
    "pst.control_data.noptmax = 0  # --> we need to run once for weight rebalancing\n",
    "\n",
    "pst.pestpp_options[\"ies_num_reals\"] = 150\n",
    "pst.pestpp_options[\"par_sigma_range\"] = 6\n",
    "pst.pestpp_options[\"ies_no_noise\"] = \"false\"\n",
    "pst.write(str(t_d / \"mv.ies.pst\"), version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c637de29",
   "metadata": {},
   "source": [
    "### copy the run folder over to be a master for parallel runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cefdf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if rundir.exists():\n",
    "    shutil.rmtree(rundir)\n",
    "shutil.copytree(t_d, rundir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdab1f89-087a-42d3-b17e-fccb13d04d79",
   "metadata": {},
   "source": [
    "## now we need to balance the objective function - we can start based on the initial run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390a2039-93a5-42fd-a81a-dace7492bdce",
   "metadata": {},
   "source": [
    "### run the model once through PEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd43aa3-f302-4754-978a-2193a6362541",
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-ies mv.ies.pst\", str(rundir))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65466bd4-f7a5-409b-8c1e-b55b9203c15e",
   "metadata": {},
   "source": [
    "### now read in the residuals and see how things look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5fb354-e916-4f73-8186-8243f507d6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new = pyemu.Pst(str(rundir / \"mv.ies.pst\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf679df-1b3b-4fa8-a2f0-6563500dafe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.plot(kind=\"phi_pie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36190b6-0006-4232-9c31-72e74205142e",
   "metadata": {},
   "source": [
    "### what are the components of the objective function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05042365-570c-495c-9afd-f41b0c4ada48",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.phi_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68899866-f5e7-434f-8ba7-df1ecbb55286",
   "metadata": {},
   "outputs": [],
   "source": [
    "phi = pst_new.phi\n",
    "phi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efef2f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REFERENCE BALANCE\n",
    "# new_components = {\n",
    "#     \"headdiffgroup\": phi * 0.15,\n",
    "#     \"headgroup\": phi * 0.225,\n",
    "#     \"lakegroup\": phi * 0.225,\n",
    "#     \"rivgroup\": phi * 0.4,\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e253a7-e467-4024-880b-b32c58cc58ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_components = {\n",
    "    \"headdiffgroup\": phi * 0.15,\n",
    "    \"headgroup\": phi * 0.225,\n",
    "    \"lakegroup\": phi * 0.225,\n",
    "    \"rivgroup\": phi * 0.4,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a8c693-329e-45f5-a9a4-81095fa6ba3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.adjust_weights(obsgrp_dict=new_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b03ba7-b7e0-406f-8ef7-03390c3b4609",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.phi_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf6cdb-771d-4971-8c75-1740c45e4121",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.plot(kind=\"phi_pie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43140e3-b4fe-4e74-b099-7c97c03ae707",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.observation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b5db1d-10fc-414c-ae29-362491441eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.control_data.noptmax = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97a8ec94-92ee-48b6-a4ed-cf5ef4a8036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_new.write(str(rundir / \"mv.ies.pst\"), version=2)\n",
    "pst_new.write(str(t_d / \"mv.ies.pst\"), version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9b29743",
   "metadata": {},
   "source": [
    "### now run the parameter estimation in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aa6a0a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_flag = True\n",
    "if run_flag:\n",
    "    pyemu.os_utils.start_workers(\n",
    "        str(t_d),\n",
    "        num_workers=15,\n",
    "        master_dir=str(rundir),\n",
    "        exe_rel_path=\"pestpp-ies\",\n",
    "        pst_rel_path=\"mv.ies.pst\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8b79df-fc19-4050-aeaf-eca0fae4994f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
